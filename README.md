## 梯度下降法
[practice0112](https://github.com/morening/LearnML/blob/master/gradient_descent/practice0112.py)

拟合 y = 2*x1 + x2 + 3

训练集 x:[[1, 2], [2, 1], [2, 3], [3, 5], [1, 3], [4, 2], [7, 3], [4, 5], [11, 3], [8, 7]]

训练集 y:[7, 8, 10, 14, 8, 13, 20, 16, 28, 26]

测试集 x:[[1, 4], [2, 2], [2, 5], [5, 3], [1, 5], [4, 1]]

**测试结果**
```
计算轮次：4009，耗时：0.434706，最小误差：0.000001
a = 2.000087
b = 1.000458
c = 2.997658
#测试：
[6.9986617712594938, 7.998290420402709, 9.9992069599056101, 14.00021041830318, 7.9991200410109435, 12.998922527943494, 19.999641554378947, 16.000297337197846, 27.999989229957613, 26.001561552279416]
#计算：
[8.999578310762395, 8.9987486901541605, 12.000123499408513, 15.99946771658961, 10.000036580513846, 11.998464258192042]
```

<img width="50%" height="50%" src="https://github.com/morening/LearnML/blob/master/snapshot/gradient_descent/practice0112.png?raw=true" />

最后，感谢[《梯度下降原理及Python实现》](http://blog.csdn.net/programmer_wei/article/details/51941358)的帮助与指导，令我深刻理解梯度下降法的原理和完成python实现。
